{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\lenovo\\vscode\\Hangman_Project\\Exploratory-Data-Analysis---Customer-Loans-in-Finance\\loan_payments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_percentage = (data.isnull().sum()/len(data)*100)\n",
    "null_percentage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['term'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['grade'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sub_grade'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['application_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['home_ownership'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['verification_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['purpose'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "null_percentage = (data.isnull().sum()/len(data)*100)\n",
    "null_percentage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows with null values in 'funded_amount'\n",
    "null_rows_data = data[data['funded_amount'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of 'funded_amount' (ignoring NaN values)\n",
    "mean_value_f = data['funded_amount'].mean()\n",
    "\n",
    "# Fill NaN values in 'funded_amount' with the mean\n",
    "data['funded_amount'] = data['funded_amount'].fillna(mean_value_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_value_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mode of 'funded_amount' (the most frequent value)\n",
    "mode_value = data['term'].mode()[0]\n",
    "\n",
    "# Fill NaN values in 'funded_amount' with the mode\n",
    "data['term'] = data['term'].fillna(mode_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(data.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns 'new' and 'month' from the DataFrame\n",
    "data = data.drop(columns=['mths_since_last_delinq', 'mths_since_last_record', 'mths_since_last_major_derog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'term' and calculate the mean of 'int_rate'\n",
    "mean_int_rate = data.groupby('term')['int_rate'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_int_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Means for each term\n",
    "mean_36_months = 12.452135\n",
    "mean_60_months = 16.635561\n",
    "\n",
    "# Fill NaN in 'int_rate' based on 'term'\n",
    "data.loc[(data['term'] == '36 months') & (data['int_rate'].isna()), 'int_rate'] = mean_36_months\n",
    "data.loc[(data['term'] == '60 months') & (data['int_rate'].isna()), 'int_rate'] = mean_60_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill the null data in next_payment_date with input of one year after last_payment_date\n",
    "# Convert 'last_payment_date' to datetime objects\n",
    "data['last_payment_date'] = pd.to_datetime(data['last_payment_date'])\n",
    "\n",
    "# Now you can add the DateOffset\n",
    "data['next_payment_date'] = data['last_payment_date'] + pd.DateOffset(years=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to datetime\n",
    "data['next_payment_date'] = pd.to_datetime(data['next_payment_date'])\n",
    "\n",
    "# Format to 'Jan-23'\n",
    "data['next_payment_date'] = data['next_payment_date'].dt.strftime('%b-%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to datetime\n",
    "data['last_payment_date'] = pd.to_datetime(data['last_payment_date'])\n",
    "\n",
    "# Format to 'Jan-23'\n",
    "data['last_payment_date'] = data['last_payment_date'].dt.strftime('%b-%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_percentage = (data.isnull().sum()/len(data)*100)\n",
    "null_percentage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mode of 'funded_amount' (the most frequent value)\n",
    "mode_value_e = data['employment_length'].mode()[0]\n",
    "\n",
    "# Fill NaN values in 'funded_amount' with the mode\n",
    "data['employment_length'] = data['employment_length'].fillna(mode_value_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_percentage = (data.isnull().sum()/len(data)*100)\n",
    "null_percentage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate skewness\n",
    "skewness = data.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define skewness threshold\n",
    "threshold = 0.80\n",
    "\n",
    "# Identify skewed columns\n",
    "skewed_columns = skewness[skewness.abs() > threshold].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Skewed Columns:\")\n",
    "print(skewed_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in skewed_columns:\n",
    "    sns.histplot(data[column], kde=True)\n",
    "    plt.title(f\"Distribution of {column} (Skew: {skewness[column]:.2f})\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "class DataFrameTransform:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def reduce_skew(self, column, method=\"log\"):\n",
    "        \"\"\"\n",
    "        Reduces skewness of a specified column using transformations.\n",
    "\n",
    "        Parameters:\n",
    "        - column (str): Column to transform.\n",
    "        - method (str): Transformation method ('log', 'sqrt', 'boxcox', 'log1p').\n",
    "\n",
    "        Returns:\n",
    "        - Transformed column (pd.Series).\n",
    "        \"\"\"\n",
    "        col_data = self.data[column]\n",
    "\n",
    "        if method == \"log\":\n",
    "            transformed = np.log(col_data[col_data > 0])\n",
    "        elif method == \"sqrt\":\n",
    "            transformed = np.sqrt(col_data[col_data >= 0])\n",
    "        elif method == \"boxcox\":\n",
    "            if col_data.min() <= 0:\n",
    "                raise ValueError(\"Box-Cox requires strictly positive values.\")\n",
    "            transformed, _ = boxcox(col_data)\n",
    "        elif method == \"log1p\":\n",
    "            transformed = np.log1p(col_data[col_data >= 0])\n",
    "        else:\n",
    "            raise ValueError(\"Invalid method. Choose from 'log', 'sqrt', 'boxcox', 'log1p'.\")\n",
    "\n",
    "        return transformed\n",
    "\n",
    "    def auto_transform_skewed(self, threshold=0.75):\n",
    "        \"\"\"\n",
    "        Identifies skewed columns and applies transformations to reduce skewness.\n",
    "\n",
    "        Parameters:\n",
    "        - threshold (float): Skewness threshold above which a column is considered skewed.\n",
    "\n",
    "        Returns:\n",
    "        - Updated DataFrame with transformed columns.\n",
    "        \"\"\"\n",
    "        skewness = self.data.skew()\n",
    "        skewed_columns = skewness[skewness.abs() > threshold].index\n",
    "\n",
    "        print(f\"Skewed Columns: {skewed_columns}\")\n",
    "        \n",
    "        for column in skewed_columns:\n",
    "            try:\n",
    "                print(f\"Transforming column: {column}\")\n",
    "                self.data[column] = self.reduce_skew(column, method=\"log1p\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error transforming column {column}: {e}\")\n",
    "\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import probplot\n",
    "def visualize_skewness(self, column, before_data, after_data):\n",
    "        \"\"\"\n",
    "        Visualize the skewness of a column before and after transformation.\n",
    "\n",
    "        Parameters:\n",
    "        - column (str): Column name.\n",
    "        - before_data (pd.Series): Column data before transformation.\n",
    "        - after_data (pd.Series): Column data after transformation.\n",
    "        \"\"\"\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "        # Histogram comparison\n",
    "        sns.histplot(before_data, kde=True, ax=axes[0], color='blue', label='Before')\n",
    "        sns.histplot(after_data, kde=True, ax=axes[0], color='orange', label='After')\n",
    "        axes[0].set_title(f\"Histogram: {column}\")\n",
    "        axes[0].legend()\n",
    "\n",
    "        # Boxplot comparison\n",
    "        sns.boxplot(data=[before_data.dropna(), after_data.dropna()], ax=axes[1])\n",
    "        axes[1].set_xticklabels(['Before', 'After'])\n",
    "        axes[1].set_title(f\"Boxplot: {column}\")\n",
    "\n",
    "        # Q-Q plot comparison\n",
    "        probplot(before_data.dropna(), dist=\"norm\", plot=axes[2])\n",
    "        probplot(after_data.dropna(), dist=\"norm\", plot=axes[2])\n",
    "        axes[2].set_title(f\"Q-Q Plot: {column}\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_skewness(self, column, before_data, after_data):\n",
    "    \"\"\"\n",
    "    Visualize the skewness of a column before and after transformation.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "    # Histogram comparison\n",
    "    sns.histplot(before_data, kde=True, ax=axes[0], color='blue', label='Before')\n",
    "    sns.histplot(after_data, kde=True, ax=axes[0], color='orange', label='After')\n",
    "    axes[0].set_title(f\"Histogram: {column}\")\n",
    "    axes[0].legend()\n",
    "\n",
    "    # Boxplot comparison\n",
    "    sns.boxplot(data=[before_data.dropna(), after_data.dropna()], ax=axes[1])\n",
    "    axes[1].set_xticklabels(['Before', 'After'])\n",
    "    axes[1].set_title(f\"Boxplot: {column}\")\n",
    "\n",
    "    # Q-Q plot comparison\n",
    "    probplot(before_data.dropna(), dist=\"norm\", plot=axes[2])\n",
    "    probplot(after_data.dropna(), dist=\"norm\", plot=axes[2])\n",
    "    axes[2].set_title(f\"Q-Q Plot: {column}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()  # Ensure plots are displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=data['total_rec_int'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the box plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.xticks(rotation=90)\n",
    "sns.boxplot(data=data, x='term', y='int_rate', color=\"skyblue\", boxprops=dict(facecolor=\"pink\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the box plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.xticks(rotation=90)\n",
    "sns.boxplot(data=data, x='term', y='loan_amount', color=\"skyblue\", boxprops=dict(facecolor=\"pink\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=data['loan_amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=data['total_payment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=data['out_prncp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the box plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.xticks(rotation=90)\n",
    "sns.boxplot(data=data, x='home_ownership', y='annual_inc', color=\"skyblue\", boxprops=dict(facecolor=\"pink\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=data['annual_inc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DataFrameTransform:\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def handle_outliers(self, columns, method=\"remove\", threshold=1.5):\n",
    "        \"\"\"\n",
    "        Handles outliers in the specified columns based on the chosen method.\n",
    "\n",
    "        Parameters:\n",
    "        - columns (list): List of column names to process.\n",
    "        - method (str): Method to handle outliers:\n",
    "            - \"remove\": Remove rows with outliers.\n",
    "            - \"replace_with_median\": Replace outliers with the median.\n",
    "            - \"replace_with_mean\": Replace outliers with the mean.\n",
    "        - threshold (float): Threshold for detecting outliers (e.g., IQR multiplier).\n",
    "        \n",
    "        Returns:\n",
    "        - pd.DataFrame: DataFrame with outliers handled.\n",
    "        \"\"\"\n",
    "        for column in columns:\n",
    "            if column not in self.dataframe:\n",
    "                print(f\"Column '{column}' not found in DataFrame.\")\n",
    "                continue\n",
    "\n",
    "            # Compute IQR\n",
    "            Q1 = self.dataframe[column].quantile(0.25)\n",
    "            Q3 = self.dataframe[column].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "\n",
    "            # Define outlier bounds\n",
    "            lower_bound = Q1 - threshold * IQR\n",
    "            upper_bound = Q3 + threshold * IQR\n",
    "\n",
    "            # Identify outliers\n",
    "            is_outlier = (self.dataframe[column] < lower_bound) | (self.dataframe[column] > upper_bound)\n",
    "\n",
    "            if method == \"remove\":\n",
    "                # Remove rows with outliers\n",
    "                self.dataframe = self.dataframe[~is_outlier]\n",
    "            elif method == \"replace_with_median\":\n",
    "                # Replace outliers with the median\n",
    "                median_value = self.dataframe[column].median()\n",
    "                self.dataframe.loc[is_outlier, column] = median_value\n",
    "            elif method == \"replace_with_mean\":\n",
    "                # Replace outliers with the mean\n",
    "                mean_value = self.dataframe[column].mean()\n",
    "                self.dataframe.loc[is_outlier, column] = mean_value\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid method: {method}. Choose 'remove', 'replace_with_median', or 'replace_with_mean'.\")\n",
    "\n",
    "        return self.dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = DataFrameTransform(data)\n",
    "\n",
    "# Handle outliers in 'feature1' and 'feature2' by removing them\n",
    "data_cleaned = transformer.handle_outliers(columns=['out_prncp', 'total_rec_int', 'last_payment_amount', 'annual_inc', 'loan_amount', 'funded_amount'], method=\"remove\")\n",
    "print(\"\\nData After Removing Outliers:\")\n",
    "print(data_cleaned)\n",
    "\n",
    "# Handle outliers by replacing with the median\n",
    "data_median = transformer.handle_outliers(columns=['out_prncp', 'total_rec_int', 'last_payment_amount', 'annual_inc', 'loan_amount', 'funded_amount'], method=\"replace_with_median\")\n",
    "print(\"\\nData After Replacing Outliers with Median:\")\n",
    "print(data_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compare original vs cleaned data\n",
    "sns.histplot(data['loan_amount'], kde=True, color=\"blue\", label=\"Original\")\n",
    "sns.histplot(data_cleaned['loan_amount'], kde=True, color=\"orange\", label=\"Cleaned\")\n",
    "plt.legend()\n",
    "plt.title(\"Outlier Handling in Feature1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compare original vs cleaned data\n",
    "sns.histplot(data['last_payment_amount'], kde=True, color=\"blue\", label=\"Original\")\n",
    "sns.histplot(data_cleaned['last_payment_amount'], kde=True, color=\"orange\", label=\"Cleaned\")\n",
    "plt.legend()\n",
    "plt.title(\"Outlier Handling in last_payment_amount\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compare original vs cleaned data\n",
    "sns.histplot(data['funded_amount'], kde=True, color=\"blue\", label=\"Original\")\n",
    "sns.histplot(data_cleaned['funded_amount'], kde=True, color=\"orange\", label=\"Cleaned\")\n",
    "plt.legend()\n",
    "plt.title(\"Outlier Handling in last_payment_amount\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "correlation_matrix = data.corr()\n",
    "\n",
    "# Visualize the correlation matrix\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_highly_correlated_columns(correlation_matrix, threshold=0.85):\n",
    "    \"\"\"\n",
    "    Finds pairs of columns with correlations above a given threshold.\n",
    "\n",
    "    Parameters:\n",
    "    - correlation_matrix (pd.DataFrame): Correlation matrix of the dataset.\n",
    "    - threshold (float): Correlation threshold.\n",
    "\n",
    "    Returns:\n",
    "    - list: List of tuples representing highly correlated column pairs.\n",
    "    \"\"\"\n",
    "    correlated_pairs = []\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i + 1, len(correlation_matrix.columns)):\n",
    "            if abs(correlation_matrix.iloc[i, j]) > threshold:\n",
    "                col1 = correlation_matrix.columns[i]\n",
    "                col2 = correlation_matrix.columns[j]\n",
    "                correlated_pairs.append((col1, col2))\n",
    "    return correlated_pairs\n",
    "\n",
    "# Identify highly correlated column pairs\n",
    "highly_correlated = find_highly_correlated_columns(correlation_matrix, threshold=0.85)\n",
    "print(\"Highly Correlated Pairs:\")\n",
    "print(highly_correlated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns_to_remove(correlated_pairs):\n",
    "    \"\"\"\n",
    "    Selects columns to remove from a list of highly correlated column pairs.\n",
    "\n",
    "    Parameters:\n",
    "    - correlated_pairs (list): List of tuples with correlated column pairs.\n",
    "\n",
    "    Returns:\n",
    "    - set: Set of columns to remove.\n",
    "    \"\"\"\n",
    "    columns_to_remove = set()\n",
    "    for col1, col2 in correlated_pairs:\n",
    "        # Keep one column and mark the other for removal (arbitrary choice here)\n",
    "        columns_to_remove.add(col2)\n",
    "    return columns_to_remove\n",
    "\n",
    "# Get columns to remove\n",
    "columns_to_remove = select_columns_to_remove(highly_correlated)\n",
    "print(\"Columns to Remove:\")\n",
    "print(columns_to_remove)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the identified columns\n",
    "data_reduced = data.drop(columns=columns_to_remove)\n",
    "print(\"Dataset after removing highly correlated columns:\")\n",
    "print(data_reduced)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
